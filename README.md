# Internship-task-1
First internship task focused on cleaning and preprocessing the Titanic dataset. Covered data exploration, handling missing values, encoding categorical data, scaling features, and removing outliers using Python, Pandas, NumPy, and Scikit-learn in Google Colab.
# Task 1 – Data Cleaning and Preprocessing

This repository contains my first internship task, which involves cleaning and preprocessing the Titanic dataset to make it ready for machine learning.

##  Overview

- Explored the dataset using Pandas
- Handled missing values:
  - Mean for numerical columns (e.g., Age)
  - Mode/default for categorical columns (e.g., Embarked, Cabin)
- Encoded categorical features:
  - Label Encoding for 'Sex'
  - One-Hot Encoding for 'Embarked'
- Scaled numerical features using StandardScaler
- Detected and removed outliers using IQR method

## Tools & Libraries Used

- Python
- Google Colab
- Pandas, NumPy
- Scikit-learn
- Seaborn, Matplotlib

##  Files

- `Titanic_Preprocessing.ipynb` – Jupyter notebook with code
- `README.md` – This file

##  Outcome

Cleaned dataset ready for machine learning model development.
